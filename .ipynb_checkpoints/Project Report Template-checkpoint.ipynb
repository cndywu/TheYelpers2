{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba5ee91",
   "metadata": {},
   "source": [
    "## Length of the report {-}\n",
    "The length of the report must be no more than 15 pages, when printed as PDF. However, there is no requirement on the minimum number of pages.\n",
    "\n",
    "You may put additional stuff as Appendix. You may refer to the Appendix in the main report to support your arguments. However, your appendix is unlikely to be checked while grading, unless the grader deems it necessary. The appendix and references will not be included in the page count, and there is no limit on the length of the appendix.\n",
    "\n",
    "**Delete this section from the report, when using this template.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3d9ed",
   "metadata": {},
   "source": [
    "## Code should be put separately in the code template {-}\n",
    "Your report should be in a research-paper like style. If there is something that can only be explained by showing the code, then you may put it, otherwise do not put the code in the report. We will check your code in the code template. \n",
    "\n",
    "However, feel free to write code that prints output and then hide the code using the *yaml* setting as shown in an example below *(in the EDA section)*\n",
    "\n",
    "# Delete this section from the report, when using this template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Background / Motivation\n",
    "\n",
    "What motivated you to work on this problem?\n",
    "\n",
    "Mention any background about the problem, if it is required to understand your analysis later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2bc7fb",
   "metadata": {},
   "source": [
    "For our project, we built a model to predict the quality of wine based on a variety of physicochemical variables. We were motivated to work on this problem since the quality of wine is something that is pretty subjective and qualitative, and we wanted to develop a model to make the process of assigning quality to wine more objective and repeatable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff1421",
   "metadata": {},
   "source": [
    "## Problem statement \n",
    "\n",
    "Describe your problem statement. Articulate your objectives using absolutely no jargon. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ee14e",
   "metadata": {},
   "source": [
    "As mentioned above, our project focused primarily on developing a regression model to predict wine quality (for this particular dataset, this value is discrete and on a scale of 0-10). We used 11 predictors – which contained information on the physicochemical properties of various wine samples – to make this prediction. We wanted to minimize MAE, although we also took note of RMSE (our approach is discussed further in a later section)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7b95f",
   "metadata": {},
   "source": [
    "## Data sources\n",
    "What data did you use? Provide details about your data. Include links to data if you are using open-access data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74182555",
   "metadata": {},
   "source": [
    "We used the “Wine Quality Data Set” datasets from UC Irvine’s Machine Learning Repository. The data came in 2 datasets – one for red wine and one for white wine. Each dataset contained  11 continuous predictors (fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulfates, alcohol) in addition to the response variable quality (which took on discrete integer values between 0 and 10). The link to download the data is http://www3.dsi.uminho.pt/pcortez/wine/  and the link to the source is https://archive.ics.uci.edu/ml/datasets/Wine+Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c255035",
   "metadata": {},
   "source": [
    "## Stakeholders\n",
    "Who cares? If you are successful, what difference will it make to them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cac9e1",
   "metadata": {},
   "source": [
    "We identified 3 key stakeholders. First, we believe that wine tasters will benefit from our model, as they can use predictions to test their ability to identify good quality wine and use the reported quality of wine as a good benchmark of comparison for testing their opinions against other industry opinions, since it is the median of three wine expert evaluations. Secondly, we believe that wine producers are a key stakeholder to consider. Using our model, wine producers can understand which of their wines is of the highest quality and price their products accordingly. Additionally, they can use this information to gauge customer and wine expert responses based on the predicted quality score for new or existing wine product offerings. Lastly, we believe that wine consumers will benefit from our model, since they can use our model to predict the quality of wine they are looking to purchase before buying it and judge the price of the wine relative to other wines of different or similar qualities to determine whether they are overpaying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data quality check / cleaning / preparation \n",
    "\n",
    "Show the distribution of the response here. Report the standard deviation and mean in case of a regression problem, and proportion of 0s and 1s in case of classification.\n",
    "\n",
    "For all other content, as mentioned below, just provide the highlights *(if any)* and put the details in the appendix.\n",
    "\n",
    "In a tabular form, show the distribution of values of each variable used in the analysis - for both categorical and continuous variables. Distribution of a categorical variable must include the number of missing values, the number of unique values, the frequency of all its levels. If a categorical variable has too many levels, you may just include the counts of the top 3-5 levels. \n",
    "\n",
    "Mention any useful insights you obtained from the data quality check that helped you develop the model or helped you realize the necessary data cleaning / preparation. Its ok if there were none.\n",
    "\n",
    "Were there any potentially incorrect values of variables that required cleaning? If yes, how did you clean them? Were there missing values? How did you handle them? Its ok if the data was already clean.\n",
    "\n",
    "Did you do any data wrangling or data preparation before the data was ready to use for model development? Did you create any new predictors from exisiting predictors? For example, if you have number of transactions and spend in a credit card dataset, you may create spend per transaction for predicting if a customer pays their credit card bill. Mention the steps at a broad level, you may put minor details in the appendix. Only mention the steps that ended up being useful towards developing your model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd74a9",
   "metadata": {},
   "source": [
    "If there is any EDA that helped with model development, put it here. If EDA didn't help then mention that, and you may show your EDA effort *(if any)* in the appendix.\n",
    "\n",
    "List the insights (as bullet points), if any, you got from EDA  that ended up being useful towards developing your final model. \n",
    "\n",
    "If there are too many plots / tables, you may put them into appendix, and just mention the insights you got from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f12d5d",
   "metadata": {},
   "source": [
    "Note that you can write code to publish the results of the code, but hide the code using the yaml setting `#|echo: false`. For example, the code below makes a plot, but the code itself is not published with Quarto in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a59729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "What kind of a models did you use? What performance metric(s) did you optimize and why?\n",
    "\n",
    "Is there anything unorthodox / new in your approach? \n",
    "\n",
    "What problems did you anticipate? What problems did you encounter? \n",
    "\n",
    "Did your problem already have solution(s) (posted on Kaggle or elsewhere). If yes, then how did you build upon those solutions, what did you do differently? Is your model better as compared to those solutions in terms of prediction accuracy or your chosen metric?\n",
    "\n",
    "**Important: Mention any code repositories (with citations) or other sources that you used, and specifically what changes you made to them for your project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5fa53",
   "metadata": {},
   "source": [
    "For our approach, we each developed a model. The models we individually developed were MARS, Bagged Decision Trees, Random Forest, and XGBoost. We wanted to optimize both RMSE and MAE. We optimized RMSE because other people in our class section tried predicting wine quality using the same dataset, and we were advised to include RMSE as a way to compare our model accuracy against theirs. We also wanted to optimize MAE because we didn’t care about penalizing large errors in prediction, as that didn’t bear much contextual significance. In terms of ways that our approach might be considered unorthodox or new / how we built upon existing solutions on Kaggle, we firstly rounded all of our model predictions to be integers, as the response variable (wine quality) only takes on discrete, integer values between 0 and 10, and we wanted our model outputs to be realistic. We additionally combined the red and white wine datasets together and created a dummy variable in the combined dataset to indicate whether the wine was red or white. This allowed us to go beyond the predictors provided and use the type of wine (red or white) as a predictor. Our model RMSE/MAE is better than all the other groups who used the same dataset in our class section – and is also on par with the accuracy of models found online. However, we did notice that there were significantly less observations that had extremely low or extremely high ratings, and we wanted our model to account for that. In order to address this, we stratified. Beyond that, we didn’t encounter many problems, as our approach was pretty straightforward. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the model: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec4c9",
   "metadata": {},
   "source": [
    "Every person must describe their hyperparameter tuning procedure. Show the grid of hyperparameter values over which the initial search was done *(you may paste your grid search / random search / any other search code)*, and the optimal hyperparameter values obtained. After getting the initial search results, how did you make decisions *(if any)* to further fine-tune your model. Did you do another grid / random search or did you tune hyperparameters sequentially? If you think you didn't need any fine tuning after the initial results, then mention that and explain why.\n",
    "\n",
    "Put each model in a section of its name and mention the name of the team-member tuning the model. Below is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea422beb",
   "metadata": {},
   "source": [
    "### MARS\n",
    "*By Cindy Wu*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393baeb",
   "metadata": {},
   "source": [
    "For the MARS model, I tuned max_degrees and max_terms. Below are the values that I simultaneously tuned over. I started off with a lot of values for my initial search then used the results from the coarse grid to narrow down the values I searched for for my finer grid. Visualizing the MAE for each coarse grid value helped a lot in identifying the optimal range, since the graph(s) showed where the MAE was lowest for each hyperparameter value (vizualizations are in Code report).\n",
    "\n",
    "**Coarse Grid:**\n",
    "max_degrees = range(1,6)\n",
    "max_terms = np.arange(10,100,20)\n",
    "\n",
    "**Finer Grid:**\n",
    "max_degrees = range(1,3)\n",
    "max_terms = np.arange(9,15,1)\n",
    "\n",
    "**Optimal hyperparameter values:**\n",
    "max_degrees = 1\n",
    "max_terms = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fbd0e",
   "metadata": {},
   "source": [
    "### Bagged Decision Trees\n",
    "*By Michael Kim*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca785c",
   "metadata": {},
   "source": [
    "For the bagged decision trees model, I first went about the approach of seeing the number of trees after which minimal improvements to OOB MAE would be seen. The visualization in the code section yielded that any number of trees above approximately 100 would be sufficient, with the value later able to be increased afterwards in final models. The hyperparameters that I chose to focus on for tuning of the BaggingRegressor() with underlying base estimators of DecisionTreeRegressor() models were n_estimators, max_samples, max_features, bootstrap, and bootstrap_features. I did not choose to tune for any hyperparameters of the base estimators because it would be computationally expensive to do so in tuning hyperparameters of each individual tree and since our primary objective in bagging was to improve the performance of the ensemble, it was more efficient to focus on the tuning of these bagging-related hyperparameters. Two processes were done with this grid searches, one for scoring with MAE and one for scoring with RMSE. I initially used a grid of hyperparameter values to initially search over shown below as the coarse grid that was often used in this course as a starting point. For RMSE, the optimal hyperparameter values from this initial grid was bootstrap = False, bootstrap_features = False, max_features = 0.75, max_samples = 1.0, n_estimators = 100. For MAE, the optimal hyperparameter values from this initial grid was bootstrap = False, bootstrap_features = True, max_features = 1.0, max_samples = 1.0, n_estimators = 100. After getting the initial search results, since the values obtained were going to hit the boundaries of these values I initially searched over, I wanted to further fine tune the grid to search over to see if these were actually ideal values for hyperparameters. I continued to do more grid searches over new grids with the range of values centered around the optimal value found in the previous grid search for each hyperparameter, which allowed me to iteratively get closer to the hyperparameter values that obtained ideal cross-validated RMSE scores (although the search ended up being extremely fine, it was not computationally expensive enough to deter me from doing this). This approach was used and visualizations were found to not be necessary, instead just using new grids and grid searches to find optimal hyperparameter values for cross-validated metrics. For MAE, the optimal hyperparameter values were bootstrap = False, bootstrap_features = False, max_features = 0.675, max_samples = 0.995, and n_estimators = 100. For RMSE, the optimal hyperparameter values were bootstrap = False, bootstrap_features = False, max_features = 0.6, max_samples = 0.99, and n_estimators = 100. Using these hyperparameter value (and increasing n_estimators to 400), performances of test RMSE: 0.6563301233138936 and test MAE: 0.3556923076923077 were obtained and were used for ensembling (from optimizing for cross-validated RMSE).\n",
    "\n",
    "**Coarse Grid:**\n",
    "n_estimators: [100],\n",
    "max_samples: [0.5, 0.75, 1.0],\n",
    "max_features: [0.5, 0.75, 1.0],\n",
    "bootstrap: [True, False],\n",
    "bootstrap_features: [True, False]\n",
    "\n",
    "**Finer Grid (scoring for RMSE):**\n",
    "n_estimators: [100],\n",
    "max_samples: [0.985, 0.99, 0.995],\n",
    "max_features: [0.625, 0.65, 0.675],\n",
    "bootstrap: [True, False],\n",
    "bootstrap_features: [True, False]\n",
    "\n",
    "**Finer Grid (scoring for MAE):**\n",
    "n_estimators: [100],\n",
    "max_samples: [0.99, 0.995, 1.0],\n",
    "max_features: [0.65, 0.675, 0.7],\n",
    "bootstrap: [True, False],\n",
    "bootstrap_features: [True, False]\n",
    "\n",
    "**Optimal hyperparameter values (for both scoring for MAE):**\n",
    "n_estimators = 100\n",
    "max_samples = 0.995\n",
    "max_features = 0.675\n",
    "bootstrap = False\n",
    "bootstrap_features = False\n",
    "\n",
    "**Optimal hyperparameter values (for both scoring for RMSE):**\n",
    "n_estimators = 100\n",
    "max_samples = 0.99\n",
    "max_features = 0.6\n",
    "bootstrap = False\n",
    "bootstrap_features = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916849c",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "*By Sabrina Kozarovitsky*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f552ef",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "*By Keaton Olds*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471fe69",
   "metadata": {},
   "source": [
    "For the XGBoost model I tuned: gamma , learning_rate, max_depth, n_estimators, reg_lambda, subsample, and colsample_bytree. I decided to tune all of these hyperparamters to ensure a thorough tuning process that would produce the best XGBoost model. To tune these hyperparamters, I began with a coarse grid, followed that up with a fine grid, followed the grid up with manual tuning, and then adjusted the paramters to reduce overfitting; the values for these are all below. With the coarse grid, I used RandomizedSearchCV with 5-fold cross validation. Through this search, I was able to select optimal values for n_estimators gamma, colsample_bytree, and subsample. I used these values in the fine grid search which I used to further narrow done values for learning_rate, reg_lambda, and max_depth. After selecting values for each of the parameters with the grid searches, I tested the model on the train data and got an RMSE of close to 0. I wanted to see if I could get the train RMSE to 0, so I tried manually tuning some of the hyperparamters on the train data, and I noticed learning_rate seemed to have an effect. To examine this relationship further, I visualized cross validation error versus learning rate, and found 0.05 to be an optimal learning rate for the train data. I implemented this change to the model, and tested it on the test data. This led to an RMSE of 0.657, which I wanted to see if I could get a little bit lower. As my train RMSE was 0.0, I figured my model was almost certaintly overfitting to the train data. To fix this, I lowered n_estimators, max_depth, and the subsample to increase bias and decrease variance, therefore correcting for overfitting. I decreased these metrics until my train RMSE was no longer 0.0, which yielded values of 300, 11, and 0.75 respectively. I decided to decrease n_estimators by that much because my visualization of MSE versus n_estimators after the coarse grid search showed that 1000 trees and 500 trees were very similar. Ultimately, this correction for overfitting yielded a final test RMSE of 0.644\n",
    "\n",
    "**Coarse Grid:** max_depth:[4,6,8], n_estimators:[100,500,1000], learning_rate:[0.01, 0.05, 0.1], subsample:[0.5,0.75,1], colsample_bytree:[0.5,0.75,1], reg_lambda:[0,1,10], gamma:[0,10,100]\n",
    "\n",
    "**Fine Grid:** max_depth:[8,9,10,11,12], n_estimators:[1000], learning_rate:[0.01, 0.03, 0.05], subsample:[1], colsample_bytree:[0.5], reg_lambda:[0,2,4,6,8], gamma:[0]\n",
    "\n",
    "**Grid Search Final Params:** max_depth:[12], n_estimators:[1000], learning_rate:[0.01], subsample:[1], colsample_bytree:[0.5], reg_lambda:[2], gamma:[0]\n",
    "\n",
    "**Manual Tuning on Train Data:** learning_rate = 0.05\n",
    "\n",
    "**Overfitting Corrections:** max_depth = 11, n_estimators = 300, subsample = 0.75\n",
    "\n",
    "**Optimal Hyperparameter Values:** max_depth = 11, n_estimators = 300, learning_rate = 0.05, subsample = 0.75, colsample_bytree = 0.5, reg_lambda = 2, gamma = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2594f1",
   "metadata": {},
   "source": [
    "## Model Ensemble "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68b0a5",
   "metadata": {},
   "source": [
    "Put the results of enembling individual models. Feel free to add subsections in this section to add more innovative ensembling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5924a",
   "metadata": {},
   "source": [
    "### Voting ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a31cb2",
   "metadata": {},
   "source": [
    "The simplest voting ensemble will be the model where all models have equal weights.\n",
    "\n",
    "You may come up with innovative methods of estimating weights of the individual models, such as based on their cross-val error. Sometimes, these methods may work better than stacking ensembles, as stacking ensembles tend to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ae2a3",
   "metadata": {},
   "source": [
    "The voting ensemble with the best cross-validated RMSE and MAE scores was that that ensembled XGBRegressor(), RandomForestRegressor(), and BaggingRegressor() models. The ensemble model test RMSE was 0.6387487769068525 and the ensemble model test MAE was 0.3464615384615385, which was lower than all the individual models. However, the best VotingRegressor() model we found on test RMSE and MAE performance actually just ensembled XGBRegressor() and RandomForestRegressor() - however, because we can only choose the best model ensembling combination based on cross-validated metrics and not on test metrics which we wouldn't normally have access to, we chose the aforementioned VotingRegressor() that ensembled three models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff4cda",
   "metadata": {},
   "source": [
    "### Stacking ensemble\n",
    "Try out different models as the metamodel. You may split work as follows. The person who worked on certain types of models *(say AdaBoost and MARS)* also uses those models as a metamodel in the stacking ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22a5f3",
   "metadata": {},
   "source": [
    "### Ensemble of ensembled models\n",
    "\n",
    "If you are creating multiple stacking ensembles *(based on different metamodels)*, you may ensemble them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe5f5f",
   "metadata": {},
   "source": [
    "### Innovative ensembling methods\n",
    "*(Optional)*\n",
    "\n",
    "Some models may do better on certain subsets of the predictor space. You may find that out, and given a data point, choose the model(s) that will best predict for that data point. This is similar to the idea of developing a decision tree metamodel. However, decision tree is prone to overfitting.\n",
    "\n",
    "Another idea may be to correct the individual models with the intercept and slope *(note the tree-based models don't have an intercept and may suffer from a constant bias)*, and then ensemble them. This is equivalent to having a simple linear regression meta-model for each of the individual models, and then ensembling the meta-models with a meta-metamodel or a voting ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46343d",
   "metadata": {},
   "source": [
    "## Limitations of the model with regard to prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ead90",
   "metadata": {},
   "source": [
    "Are you confident that you found the optimal hyperparameter values for each of your individual models, and that your individual models cannot be better tuned? Or, are there any models that could be better tuned if you had more time / resources, but you are limited by the amount of time you can spend on the course project *(equivalent to one assignment)*? If yes, then which models could be better tuned and how?\n",
    "\n",
    "Will it be possible / convenient / expensive for the stakeholders to collect the data relating to the predictors in the model. Using your model, how soon will the stakeholder be able to predict the outcome before the outcome occurs. For example, if the model predicts the number of bikes people will rent in Evanston on a certain day, then how many days before that day will your model be able to make the prediction. This will depend on how soon the data that your model uses becomes available. If you are predicting election results, how many days / weeks / months / years before the election can you predict the results. \n",
    "\n",
    "When will your model become too obsolete to be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6026cb7",
   "metadata": {},
   "source": [
    "## Other sections *(optional)*\n",
    "\n",
    "You are welcome to introduce additional sections or subsections, if required, to address any specific aspects of your project in detail. For example, you may briefly discuss potential future work that the research community could focus on to make further progress in the direction of your project's topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations to stakeholder(s)\n",
    "\n",
    "What conclusions do you draw based on your model? You may draw conclusions based on prediction accuracy, or other performance metrics.\n",
    "\n",
    "How do you use those conclusions to come up with meaningful recommendations for stakeholders? The recommendations must be action-items for stakeholders that they can directly implement without any further analysis. Be as precise as possible. The stakeholder(s) are depending on you to come up with practically implementable recommendations, instead of having to think for themselves.\n",
    "\n",
    "If your recommendations are not practically implementable by stakeholders, how will they help them? Is there some additional data / analysis / domain expertise you need to do to make the recommendations implementable? \n",
    "\n",
    "Do the stakeholder(s) need to be aware about some limitations of your model? Is your model only good for one-time use, or is it possible to update your model at a certain frequency (based on recent data) to keep using it in the future? If it can be used in the future, then for how far into the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b0ddc",
   "metadata": {},
   "source": [
    "From this, we can conclude that by using physicochemical properties, wine consumers and critics can get a reasonably accurate standard of comparison for the quality of the wine (regardless of whether it is red or white). Our final model had a RMSE of 0.63 and MAE of 0.34, indicating that the average absolute error (difference between predictions and true values) is small enough to not round to another integer. In other words, our prediction accuracy is good enough to use! Additionally, we found that the physicochemical features that are most important in predicting quality are type of wine and alcohol.  \n",
    "\n",
    "In terms of action items, given our model accuracy, Vinho Verde wine producers can input physicochemical property data for different wines into our predictive ensemble model and get wine quality predictions with absolute differences that round to a single quality score. Although the dataset is only applicable to Vinho Verde wines, using new data for other regional wine varieties with the same techniques can yield similar results and accuracy in predictions. Similarly, consumers and tasters of Vinho Verde wine can input  physicochemical property data for different wines into our predictive ensemble model and get an accurate understanding of the quality of wine they are drinking and/or purchasing. In general, we believe that our model is pretty interpretable and our recommendations are very implementable. \n",
    "\n",
    "Our model definitely is capable of being updated and is not only good for one-time use. It’s possible to continue updating the data with more ratings (since it’s currently only the median of three wine expert evaluations). So as more trusted wine expert evaluations are conducted, we can add that to our dataset and redevelop the model to make it more accurate to current industry ratings/trends. Given this approach and the ability for our model to continuously adapt and improve based on new information/ratings, our model can be used pretty far into the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca45613",
   "metadata": {},
   "source": [
    "Add details of each team member's contribution, other than the models contributed, in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505da5c",
   "metadata": {},
   "source": [
    "<html>\n",
    "<style>\n",
    "table, td, th {\n",
    "  border: 1px solid black;\n",
    "}\n",
    "\n",
    "table {\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "th {\n",
    "  text-align: left;\n",
    "}\n",
    "    \n",
    "\n",
    "</style>\n",
    "<body>\n",
    "\n",
    "<h2>Individual contribution</h2>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "     <colgroup>\n",
    "       <col span=\"1\" style=\"width: 15%;\">\n",
    "       <col span=\"1\" style=\"width: 20%;\">\n",
    "       <col span=\"1\" style=\"width: 25%;\">\n",
    "       <col span=\"1\" style=\"width: 40%;\">\n",
    "    </colgroup>\n",
    "  <tr>\n",
    "    <th>Team member</th>\n",
    "    <th>Individual Model</th>\n",
    "    <th>Work other than individual model</th>    \n",
    "    <th>Details of work other than individual model</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Cindy Wu</td>\n",
    "    <td>MARS</td>\n",
    "    <td>Data cleaning and EDA</td>    \n",
    "    <td>Imputed missing values and visualized data</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Michael Kim</td>\n",
    "    <td>Bagged Decision Trees</td>\n",
    "    <td>Ensembling</td>    \n",
    "    <td>Stacking ensembles and voting ensemble</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Sabrina Kozarovitsky</td>\n",
    "    <td>Random forest</td>\n",
    "    <td>Variable selection</td>    \n",
    "    <td>Variable selection based on feature importance</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Keaton Olds</td>\n",
    "    <td>XGBoost</td>\n",
    "    <td>Data Preparation</td>    \n",
    "    <td>Innovative ensemble & stacking ensemble</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1cafe",
   "metadata": {},
   "source": [
    "## References {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb1aad",
   "metadata": {},
   "source": [
    "List and number all bibliographical references. When referenced in the text, enclose the citation number in square brackets, for example [1].\n",
    "\n",
    "[1] Authors. The frobnicatable foo filter, 2014. Face and Gesture submission ID 324. Supplied as additional material\n",
    "fg324.pdf. 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831751c",
   "metadata": {},
   "source": [
    "## Appendix {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d374d",
   "metadata": {},
   "source": [
    "You may put additional stuff here as Appendix. You may refer to the Appendix in the main report to support your arguments. However, the appendix section is unlikely to be checked while grading, unless the grader deems it necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
