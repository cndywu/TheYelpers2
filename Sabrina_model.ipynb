{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c612e3f",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e05081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, \\\n",
    "accuracy_score, precision_score, confusion_matrix, mean_squared_error, r2_score\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "#Libraries for visualizing trees\n",
    "from sklearn.tree import export_graphviz \n",
    "from six import StringIO\n",
    "from IPython.display import Image\n",
    "import time as time\n",
    "\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389c4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_train = pd.read_csv('red_train.csv')\n",
    "red_test = pd.read_csv('red_test.csv')\n",
    "white_train = pd.read_csv('white_train.csv')\n",
    "white_test = pd.read_csv('white_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3972e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_train_copy = red_train.copy()\n",
    "red_test_copy = red_test.copy()\n",
    "white_train_copy = white_train.copy()\n",
    "white_test_copy = white_test.copy()\n",
    "red_train_copy['type'] = 'red'\n",
    "red_test_copy['type'] = 'red'\n",
    "white_train_copy['type'] = 'white'\n",
    "white_test_copy['type'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d086ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = pd.concat([red_train_copy, white_train_copy], axis = 0)\n",
    "combined_test = pd.concat([red_test_copy, white_test_copy], axis = 0)\n",
    "combined_train = pd.get_dummies(combined_train)\n",
    "combined_test = pd.get_dummies(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4217ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_train_x = red_train.drop('quality', axis = 1)\n",
    "red_train_y = red_train['quality']\n",
    "red_test_x = red_test.drop('quality', axis = 1)\n",
    "red_test_y = red_test['quality']\n",
    "white_train_x = white_train.drop('quality', axis = 1)\n",
    "white_train_y = white_train['quality']\n",
    "white_test_x = white_test.drop('quality', axis = 1)\n",
    "white_test_y = white_test['quality']\n",
    "combined_train_x = combined_train.drop('quality', axis = 1)\n",
    "combined_train_y = combined_train['quality']\n",
    "combined_test_x = combined_test.drop('quality', axis = 1)\n",
    "combined_test_y = combined_test['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6305b890",
   "metadata": {},
   "source": [
    "# Create Base RandomForest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "173727c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.559647433658013\n",
      "MAE: 0.407175\n"
     ]
    }
   ],
   "source": [
    "#Red\n",
    "base_model_red = RandomForestRegressor().fit(red_train_x, red_train_y)\n",
    "y_pred = base_model_red.predict(red_test_x)\n",
    "\n",
    "#RMSE on test data\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(red_test_y, y_pred)))\n",
    "#MAE on test data\n",
    "print(\"MAE:\",mean_absolute_error(red_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f66a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6382078223351668\n",
      "MAE: 0.45294693877551023\n"
     ]
    }
   ],
   "source": [
    "#White\n",
    "base_model_white = RandomForestRegressor().fit(white_train_x, white_train_y)\n",
    "y_pred = base_model_white.predict(white_test_x)\n",
    "\n",
    "#RMSE on test data\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(white_test_y, y_pred)))\n",
    "#MAE on test data\n",
    "print(\"MAE:\",mean_absolute_error(white_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e98ff5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6238069721168067\n",
      "MAE: 0.44387692307692306\n"
     ]
    }
   ],
   "source": [
    "#Combined\n",
    "base_model_combined = RandomForestRegressor().fit(combined_train_x, combined_train_y)\n",
    "y_pred = base_model_combined.predict(combined_test_x)\n",
    "\n",
    "#RMSE on test data\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(combined_test_y, y_pred)))\n",
    "#MAE on test data\n",
    "print(\"MAE:\",mean_absolute_error(combined_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cfdea",
   "metadata": {},
   "source": [
    "# Tuning Red Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7869971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters :  {'bootstrap': False, 'max_features': 2, 'n_estimators': 850}\n"
     ]
    }
   ],
   "source": [
    "n_samples = red_train_x.shape[0]\n",
    "n_features = red_train_x.shape[1]\n",
    "\n",
    "params = {'n_estimators': [700, 850],\n",
    "          'max_features': list(range(2,8,2)),\n",
    "          'bootstrap': [True, False]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "rf_regressor_grid = GridSearchCV(RandomForestRegressor(random_state=1, n_jobs=-1), \n",
    "                                      param_grid =params, cv=cv, n_jobs=-1, verbose=1, scoring='neg_mean_absolute_error')\n",
    "rf_regressor_grid.fit(red_train_x, red_train_y)\n",
    "print('Best Parameters : ',rf_regressor_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "364c07ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5496370586066515\n",
      "MAE: 0.3714382352941176\n"
     ]
    }
   ],
   "source": [
    "# Red Model with optimal parameters\n",
    "optimal_model_red = RandomForestRegressor(n_estimators=850, random_state=1,\n",
    "                                          bootstrap = False,n_jobs=-1, max_features=2).fit(red_train_x, red_train_y)\n",
    "\n",
    "y_pred = optimal_model_red.predict(red_test_x)\n",
    "\n",
    "#RMSE on test data\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(red_test_y, y_pred)))\n",
    "#MAE on test data\n",
    "print(\"MAE:\",mean_absolute_error(red_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eac9f277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5441681184858873\n",
      "MAE: 0.3612529411764706\n"
     ]
    }
   ],
   "source": [
    "#Further tuning red model with intuition\n",
    "intuition_model_red = RandomForestRegressor(n_estimators=850, random_state=1,\n",
    "                                          bootstrap = False,n_jobs=-1, max_features=7).fit(red_train_x, red_train_y)\n",
    "\n",
    "y_pred = intuition_model_red.predict(red_test_x)\n",
    "\n",
    "#RMSE on test data\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(red_test_y, y_pred)))\n",
    "#MAE on test data\n",
    "print(\"MAE:\",mean_absolute_error(red_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c4449",
   "metadata": {},
   "source": [
    "# Tuning White Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a22f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters :  {'bootstrap': False, 'max_features': 2, 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "n_samples = white_train_x.shape[0]\n",
    "n_features = white_train_x.shape[1]\n",
    "\n",
    "params = {'n_estimators': [700, 850],\n",
    "          'max_features': list(range(2,8,2)),\n",
    "          'bootstrap': [True, False]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "rf_regressor_grid = GridSearchCV(RandomForestRegressor(random_state=1, n_jobs=-1), \n",
    "                                      param_grid =params, cv=cv, n_jobs=-1, verbose=1, scoring='neg_mean_absolute_error')\n",
    "rf_regressor_grid.fit(white_train_x, white_train_y)\n",
    "print('Best Parameters : ',rf_regressor_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d2a7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.616714316442351\n",
      "MAE: 0.39846880466472306\n"
     ]
    }
   ],
   "source": [
    "# White Model with optimal parameters\n",
    "optimal_model_white = RandomForestRegressor(n_estimators=700, random_state=1, max_features = 2, bootstrap = False).fit(white_train_x, white_train_y)\n",
    "\n",
    "y_pred = optimal_model_white.predict(white_test_x)\n",
    "\n",
    "#RMSE on test data\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(white_test_y, y_pred)))\n",
    "#MAE on test data\n",
    "print(\"MAE:\",mean_absolute_error(white_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe98816",
   "metadata": {},
   "source": [
    "# Tuning Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71021cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Parameters :  {'bootstrap': False, 'max_features': 2, 'n_estimators': 850}\n"
     ]
    }
   ],
   "source": [
    "n_samples = combined_train_x.shape[0]\n",
    "n_features = combined_train_x.shape[1]\n",
    "\n",
    "params = {'n_estimators': [700, 850, 900],\n",
    "          'max_features': list(range(2,8,2)),\n",
    "          'bootstrap': [True, False]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "rf_regressor_grid = GridSearchCV(RandomForestRegressor(random_state=1, n_jobs=-1), \n",
    "                                      param_grid =params, cv=cv, n_jobs=-1, verbose=1, scoring='neg_mean_absolute_error')\n",
    "rf_regressor_grid.fit(combined_train_x, combined_train_y)\n",
    "print('Best Parameters : ',rf_regressor_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2316ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6049172178553129\n",
      "MAE: 0.39452018099547514\n"
     ]
    }
   ],
   "source": [
    "# Combined Model with optimal parameters\n",
    "optimal_model_combined = RandomForestRegressor(n_estimators=850, random_state=1, max_features = 2, bootstrap = False).fit(combined_train_x, combined_train_y)\n",
    "\n",
    "y_pred = optimal_model_combined.predict(combined_test_x)\n",
    "\n",
    "#RMSE on test data\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(combined_test_y, y_pred)))\n",
    "#MAE on test data\n",
    "print(\"MAE:\",mean_absolute_error(combined_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3552dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6040048809591836\n",
      "MAE: 0.39270139017608896\n"
     ]
    }
   ],
   "source": [
    "# Further tuning combined Model with intuition\n",
    "optimal_model_combined = RandomForestRegressor(n_estimators=830, random_state=1, max_features = 3, bootstrap = False).fit(combined_train_x, combined_train_y)\n",
    "\n",
    "y_pred = optimal_model_combined.predict(combined_test_x)\n",
    "\n",
    "#RMSE on test data\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(combined_test_y, y_pred)))\n",
    "#MAE on test data\n",
    "print(\"MAE:\",mean_absolute_error(combined_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210db9d",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00b3e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Base MAE: 0.407175\n",
      "Red Tuned MAE: 0.3612529411764706\n",
      "Improvement: 11.28 %\n"
     ]
    }
   ],
   "source": [
    "# red\n",
    "print(\"Red Base MAE: 0.407175\")\n",
    "print(\"Red Tuned MAE: 0.3612529411764706\")\n",
    "\n",
    "improvement = 100*((0.407175-0.3612529411764706)/0.407175)\n",
    "print(\"Improvement:\", str(round(improvement, 2)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f31cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Base MAE: 0.45294693877551023\n",
      "White Tuned MAE: 0.39846880466472306\n",
      "Improvement: 12.03 %\n"
     ]
    }
   ],
   "source": [
    "# white\n",
    "print(\"White Base MAE: 0.45294693877551023\")\n",
    "print(\"White Tuned MAE: 0.39846880466472306\")\n",
    "\n",
    "improvement = 100*((0.45294693877551023-0.39846880466472306)/0.45294693877551023)\n",
    "print(\"Improvement:\", str(round(improvement, 2)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d20958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined\n",
    "print(\"Combined Base MAE: 0.44387692307692306\")\n",
    "print(\"Combined Tuned MAE: 0.39846880466472306\")\n",
    "\n",
    "improvement = 100*((0.45294693877551023-0.39846880466472306)/0.45294693877551023)\n",
    "print(\"Improvement:\", str(round(improvement, 2)), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
